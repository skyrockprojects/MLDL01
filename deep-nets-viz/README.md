# deep-nets-viz

In this session, we'll take (another) great leap - this time into some of the most popular and best performing models available to the public. It would take a PhD to understand it all, so we will focus on a specific objective - how can we visualize what these models are learning?
To do so, we will dive deep into the many hidden layers of models such as Googles Inception. By utilizing some clever techniques, we can find out what these models learn at different layers. The results are often quite interesting and the potential quite exciting. Possibilities abound, and the code awaits..

```viz-techniques```
try:
1. Implement one or more of the visualization techniques on a previous session's code
2. Create a gif from your visualization of a previous session's code

```feature-viz-ddream```
1. Visualize at least 3 different feature channels at 3 different layers
2. Create a gif for the "deep dream" technique

```tf-hub-gen..```
1. Visualize the most realistic deep fake you can
2. How can people tell a fake from a real celebrity?
3. Make changes to a deep fake while maintaining the identity
4. Use vector math (add and/or subtract positions) to find meaningful relationships between features

### Sources and Resources
1. [Distill pub's awesome feature visualization blog/code](https://distill.pub/2017/feature-visualization/)
2. [Google tf-hub deep fakes](https://www.tensorflow.org/hub/modules/google/progan-128/1)

### TO-DO: save out jpg w/ deepfakes and 3d model them here: http://cvl-demos.cs.nott.ac.uk/vrn/
